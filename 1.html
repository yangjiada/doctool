<html><head></head><body><blockquote>原文：<a href="https://docs.scrapy.org/en/latest/intro/overview.html"> https://docs.scrapy.org/en/latest/intro/overview.html </a></blockquote>
<span id="intro-overview"></span><h1>Scrapy一目了然</h1>
<p>Scrapy是一种用于抓取网站和提取结构化数据的应用程序框架，可用于广泛的有用应用程序，如数据挖掘，信息处理或历史存档。</p>
<p>尽管Scrapy最初是为<a class="reference external" href="https://en.wikipedia.org/wiki/Web_scraping">网页抓取</a>设计的，但它也可以用于使用API​​（例如<a class="reference external" href="https://affiliate-program.amazon.com/gp/advertising/api/detail/main.html"> Amazon Associates Web Services </a>）或作为通用网络爬虫来提取数据。</p>
<div class="section" id="walk-through-of-an-example-spider">
<h2>一个示例蜘蛛的走过</h2>
<p>为了向您展示Scrapy带来的内容，我们将以最简单的方式运行蜘蛛，向您介绍Scrapy Spider的示例。</p>
<p>这是一个蜘蛛的代码，它在网页<a class="reference external" href="http://quotes.toscrape.com"> http://quotes.toscrape.com </a>上删除着名的引号，然后分页：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">'quotes'</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">'http://quotes.toscrape.com/tag/humor/'</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'div.quote'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">'text'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'span.text::text'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">'author'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">'span/small/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'li.next a::attr("href")'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<p>把它放在一个文本文件中，将其命名为<code class="docutils literal notranslate"> <span class="pre"> quotes_spider.py </span> </code>并使用<a class="reference internal" href="../topics/commands.html#std:command-runspider"> <code class="xref std std-command docutils literal notranslate"> <span class="pre"> runspider </span> </code> [运行蜘蛛] HTG9]命令：</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">runspider</span> <span class="n">quotes_spider</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">o</span> <span class="n">quotes</span><span class="o">.</span><span class="n">json</span>
</pre></div>
</div>
<p>完成后，您将在<code class="docutils literal notranslate"> <span class="pre"> quotes.json </span> </code>文件中包含JSON格式的引号列表，其中包含文本和作者，如下所示（为了更好的可读性，此处重新格式化）：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[{</span>
    <span class="s2">"author"</span><span class="p">:</span> <span class="s2">"Jane Austen"</span><span class="p">,</span>
    <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"</span><span class="se">\u201c</span><span class="s2">The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.</span><span class="se">\u201d</span><span class="s2">"</span>
<span class="p">},</span>
<span class="p">{</span>
    <span class="s2">"author"</span><span class="p">:</span> <span class="s2">"Groucho Marx"</span><span class="p">,</span>
    <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"</span><span class="se">\u201c</span><span class="s2">Outside of a dog, a book is man's best friend. Inside of a dog it's too dark to read.</span><span class="se">\u201d</span><span class="s2">"</span>
<span class="p">},</span>
<span class="p">{</span>
    <span class="s2">"author"</span><span class="p">:</span> <span class="s2">"Steve Martin"</span><span class="p">,</span>
    <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"</span><span class="se">\u201c</span><span class="s2">A day without sunshine is like, you know, night.</span><span class="se">\u201d</span><span class="s2">"</span>
<span class="p">},</span>
<span class="o">...</span><span class="p">]</span>
</pre></div>
</div>
<div class="section" id="what-just-happened">
<h3>刚刚发生了什么？</h3>
<p>当您运行命令<code class="docutils literal notranslate"> <span class="pre"> scrapy </span> <span class="pre"> runspider </span> <span class="pre"> quotes_spider.py </span> </code>时，Scrapy在其中查找Spider定义并通过其爬虫引擎运行它。</p>
<p>通过向<code class="docutils literal notranslate"> <span class="pre"> start_urls </span> </code>属性中定义的URL发出请求（在这种情况下，只有<em> humor </em>类别中的引号的URL）并且调用默认值回调方法<code class="docutils literal notranslate"> <span class="pre">解析</span> </code>，将响应对象作为参数传递。在<code class="docutils literal notranslate"> <span class="pre">解析</span> </code>回调中，我们使用CSS Selector循环遍历quote元素，生成带有提取的引用文本和作者的Python dict，查找指向下一页和日程表的链接另一个请求使用相同的<code class="docutils literal notranslate"> <span class="pre">解析</span> </code>方法作为回调。</p>
<p>在这里你会注意到Scrapy的一个主要优点：请求<a class="reference internal" href="../topics/architecture.html#topics-architecture"> <span class="std std-ref">被异步调度和处理</span> </a>。这意味着Scrapy不需要等待请求完成和处理，它可以在此期间发送另一个请求或执行其他操作。这也意味着即使某些请求失败或在处理错误时发生错误，其他请求也可以继续运行。</p>
<p>虽然这使您能够进行非常快速的爬网（以容错的方式同时发送多个并发请求），Scrapy还可以通过<a class="reference internal" href="../topics/settings.html#topics-settings-ref"> <span class="std std-ref">进行一些设置</span>来控制爬行的礼貌</a>。您可以执行以下操作：在每个请求之间设置下载延迟，限制每个域或每个IP的并发请求数量，甚至<a class="reference internal" href="../topics/autothrottle.html#topics-autothrottle"> <span class="std std-ref">使用自动限制扩展</span> </a>试图找出这些自动。</p>
<div class="admonition note">
<p class="first admonition-title">注意</p>
<p class="last">这是使用<a class="reference internal" href="../topics/feed-exports.html#topics-feed-exports"> <span class="std std-ref"> Feed导出</span> </a>生成JSON文件，您可以轻松更改导出格式（例如XML或CSV）或存储后端（FTP或<a class="reference external" href="https://aws.amazon.com/s3/"> Amazon S3 </a>，例如）。您还可以编写<a class="reference internal" href="../topics/item-pipeline.html#topics-item-pipeline"> <span class="std std-ref">项目管道</span> </a>来存储数据库中的项目。</p>
</div>
</div>
</div>
<div class="section" id="what-else">
<span id="topics-whatelse"></span><h2>还有什么？</h2>
<p>您已经了解了如何使用Scrapy从网站中提取和存储项目，但这只是表面。 Scrapy提供了许多强大的功能，可以轻松高效地进行抓取，例如：</p>
<ul class="simple">
<li>内置支持<a class="reference internal" href="../topics/selectors.html#topics-selectors"> <span class="std std-ref">使用扩展的CSS选择器和XPath表达式从HTML / XML源中选择和提取</span> </a>数据，并使用正则表达式提取辅助方法。</li>
<li>一个<a class="reference internal" href="../topics/shell.html#topics-shell"> <span class="std std-ref">交互式shell控制台</span> </a>（知道IPy）用于尝试使用CSS和XPath表达式来抓取数据，在编写或调试蜘蛛时非常有用。</li>
<li>内置支持<a class="reference internal" href="../topics/feed-exports.html#topics-feed-exports"> <span class="std std-ref">以多种格式（JSON，CSV，XML）生成Feed </span> </a>并将其存储在多个后端（FTP，S3，本地文件系统）中</li>
<li>强大的编码支持和自动检测，用于处理外部，非标准和损坏的编码声明。</li>
<li><a class="reference internal" href="../index.html#extending-scrapy"> <span class="std std-ref">强大的可扩展性支持</span> </a>，允许您使用<a class="reference internal" href="../topics/signals.html#topics-signals"> <span class="std std-ref">信号</span> </a>和定义良好的API（中间件，<a class="reference internal" href="../topics/extensions.html#topics-extensions">）插入您自己的功能<span class="std std-ref">扩展</span> </a>和<a class="reference internal" href="../topics/item-pipeline.html#topics-item-pipeline"> <span class="std std-ref">管道</span> </a>）。</li>
<li>广泛的内置扩展和中间件用于处理：<ul>
<li>cookie和会话处理</li>
<li>HTTP功能，如压缩，身份验证，缓存</li>
<li>用户代理欺骗</li>
<li>的robots.txt</li>
<li>爬行深度限制</li>
<li>和更多</li>
</ul></li>
<li>一个<a class="reference internal" href="../topics/telnetconsole.html#topics-telnetconsole"> <span class="std std-ref"> Telnet控制台</span> </a>用于连接到Scrapy进程内部运行的Python控制台，以便对您的爬虫进行内省和调试</li>
<li>还有其他好东西，比如可重复使用的蜘蛛来自<a class="reference external" href="https://www.sitemaps.org/index.html">站点地图</a>和XML / CSV源，<a class="reference internal" href="../topics/media-pipeline.html#topics-media-pipeline"> <span class="std std-ref">的媒体管道，可以自动下载与之相关的图像</span> </a>（或任何其他媒体）已删除的项目，缓存DNS解析器等等！</li>
</ul>
</div>
<div class="section" id="what-s-next">
<h2>下一步是什么？</h2>
<p>接下来的步骤是<a class="reference internal" href="install.html#intro-install"> <span class="std std-ref">安装Scrapy </span> </a>，<a class="reference internal" href="tutorial.html#intro-tutorial"> <span class="std std-ref">按照教程</span> </a>学习如何创建一个完整的Scrapy项目和<a class="reference external" href="https://scrapy.org/community/">加入社区</a>。谢谢你的关注！</p>
</div>
</body></html>